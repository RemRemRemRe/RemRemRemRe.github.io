[
  
  {
    "title": "My Understanding of the Unreal Animation Framework in 5.6",
    "url": "/posts/My-understanding-of-Unreal-Animation-Framework-in-5.6/",
    "categories": "Unreal Engine, Animation",
    "tags": "gameplay, animation, tutorial",
    "date": "2025-08-05 01:50:00 +0800",
    "content": "About two months ago, the technical demonstration of The Witcher 4 at Unreal Fest showcased the next-generation animation system of the Unreal Engine (Unreal Animation Framework, hereafter referred to as UAF, while the previous animation blueprint system will be referred to as ABP). This sparked my strong curiosity, and I felt it was time to dive into understanding this system.  This article will analyze the system from a architecture perspective, primarily introducing its components, the meanings of various types, and their logical relationships. I hope this will help everyone grasp and get started with this new animation system, but it will not cover details such as animation blending calculations or animation retargeting.  Simple demo  Let’s start with a simple demo:    The video shows a simple layered blending effect, with the upper body coming from the static frame of the bow drawing animation and the lower body using a looping sprint animation.  BlendMask utilizes a HierarchyTable:       It is a general-purpose hierarchical data container, used here as BlendProfile   From the left view, it’s clear that the two models completely overlap, and the animation effects are identical:    This is because both are running the same animation graph of UAF:       The upper left is the lower body animation, the lower left is the upper body animation, and the right is the layered blending   The difference is that the animation graph on the left is updated using the UAF framework:       These nodes here may not be the optimal implementation, but they are sufficient for simple demonstration   while on the right side, the animation graph is updated using ABP :       animation graph of UAF can be integrated into animation blueprints through this special animation node   Unified Workspace Interface  UAF has integrated the Workspace Editor, providing a unified view of multiple assets. The workspace itself also has a corresponding asset, classified as UAF Workspace, which should be used to store metadata related to the workspace.     The Workspace Editor module comes from the new experimental plugin Workspace, which allows multiple assets to be edited in a unified interface.    UAF has integrated this feature, which specifies that UAF-related asset types can be edited in the same workspace.    See：UAnimNextWorkspaceSchema, IWorkspaceEditorModule::RegisterObjectDocumentType   The workspace tab in the upper left corner lists the assets opened in the current workspace:    Namely, AG_SequencePlayer, UAFM_Module, and the workspace’s own asset: UAFW_Workspace:    System Composition     These raw cpp types bellow are basically located in the UE::AnimNext namespace   The logical carriers of UAF currently consist of two main components: Module and AnimationGraph, both running within RigVM, supporting multithreaded execution.      Data exchange between threads is accomplished through UAnimNextComponent::PublicVariablesProxy.  The comment in FAnimNextPublicVariablesProxy mentions that currently, it copies dirty-marked data every frame, with plans to change it to a double-buffered array in the future (refer to USkinnedMeshComponent::ComponentSpaceTransformsArray).     See：    FAnimNextModuleInstance::CopyProxyVariables    IAnimNextVariableProxyHost::FlipPublicVariablesProxy    UAnimNextComponent::SetVariable    UAnimNextComponentWorldSubsystem::Register   Module  The module here is where various functions are used to write logical business, similar to the blueprint section in ABP / UAnimInstance::NativeUpdateAnimation, UAnimInstance::NativeThreadSafeUpdateAnimation, but more powerful and flexible.  FRigUnit_AnimNextModuleEventBase：    Through the interface provided by the base class, each module can choose whether it needs an independent TickFunction, which Tick Group to run in, whether to operate on the game thread, and other functionalities.  The UAF compiler will also automatically generate some modules, such as variable binding-related FRigUnit_AnimNextExecuteBindings_GT and FRigUnit_AnimNextExecuteBindings_WT.  AnimationGraph  The animation graph is a collection of animation logic and its data, similar to the animation tree in ABP.  The difference is that in UAF, there are no longer various animation nodes; instead, there is a TraitStack node combined with various Trait combinations.  The animation graph itself acts as a UObject, also holding references to UObject references that referenced by shared data within the graph, preventing them from being garbage collected.     See：    UAnimNextAnimationGraph::GraphReferencedObjects    UAnimNextAnimationGraph::GraphReferencedSoftObjects   Additionally, animated charts can have multiple entries, not just Root  TraitStack and TraitStack Node  TraitStack: As the name suggests, this is a stack structure composed of Traits, which includes 1 base trait and several additive traits.  The corresponding node is simply a standard RigUnit node (struct):    A TraitStack node can contain one or more TraitStacks.  In the editor, it appears as shown in the layered blending animation graph above.     The node form is just for the convenience of visualization in the editor. After compiling, the corresponding TraitStack will be serialized into the animation graph. This RigUnit node will not be executed   Trait  “trait” or feature, it refers to reusable functionalities in animation logic, similar to animation nodes in ABP, but again, more powerful and flexible.  FTrait  FTrait is the base class for all Traits, defining the necessary basic interface, such as obtaining its unique ID.    Derived traits are composed of FBaseTrait or FAdditiveTrait along with the derived interface class of ITraitInterface.      ITraitInterface is the base class for all trait interfaces.    It contains only one method for getting UID, meaning each trait interface also has a unique ID.  Currently, these two unique IDs are derived by applying the FNV1a hash algorithm to the class name. This algorithm is characterized by the fact that for the same character combination, whether the characters are normal characters or wide characters, it does not affect the hash result, producing the same hash value, and is simple and efficient.     See：    FTraitUID::MakeUID    FTraitInterfaceUID::MakeUID   Trait objects themselves cannot have internal state, meaning they are stateless, as their logic runs in worker threads (for example, multiple objects reusing the same animation graph within the same frame execute in different threads).  Their state data should be declared using the type aliases FSharedData and FInstanceData, which the UAF system will allocate externally for the Trait objects.    FSharedData is read-only data that can be shared among multiple instances of the same animation graph; it is a USTRUCT that will serialize and save to a file, typically consisting of some hardcoded configurations.  FInstanceData contains the dynamic/instanced data required by the nodes in each animation graph instance and is a raw CPP structure.     FSharedData is similar to FoldProperty in ABP,    while the mechanism of InstanceData is almost the same as FInstanceDataType/UInstanceDataType in StateTree   Code Generation  UAF uses several macros to quickly and easily generate the code required for the framework, reducing repetitive work.  Macros for Trait Interface  The trait interface part is relatively simple, with only two macros.  DECLARE_ANIM_TRAIT_INTERFACE declares and implements GetInterfaceUID, returning a compile-time constant:      AUTO_REGISTER_ANIM_TRAIT_INTERFACE statically registers the shared pointer of the trait interface class to the global trait interface registry:    Macros for Trait  The trait section is considerably more complex:  First, you need to use the DECLARE_ANIM_TRAIT macro within the trait class to declare some virtual function overrides:    This includes several nested macros:  ANIM_NEXT_IMPL_DECLARE_ANIM_TRAIT_BASIC declares and implements GetTraitUID, returning a compile-time constant; GetTraitName returns the trait name; declares an alias for TraitSuper.  ANIM_NEXT_IMPL_DECLARE_ANIM_TRAIT_INSTANCING_SUPPORT add declarations related to trait data.  ANIM_NEXT_IMPL_DECLARE_ANIM_TRAIT_INTERFACE_SUPPORT add declarations for accessing the trait interface.  ANIM_NEXT_IMPL_DECLARE_ANIM_TRAIT_EVENT_SUPPORT add declarations related to trait events.  ANIM_NEXT_IMPL_DECLARE_ANIM_TRAIT_LATENT_PROPERTY_SUPPORT add declarations related to Latent Property (see below for the meaning of Latent Property).  Then, use the GENERATE_ANIM_TRAIT_IMPLEMENTATION macro to define the above interfaces.    Notably, the parameters InterfaceEnumeratorMacro, RequiredInterfaceEnumeratorMacro, EventEnumeratorMacro are all EnumeratorMacros, which are macros used for enumeration, with their prefixes indicating what they enumerate: trait interface, required trait interface, and trait events.  The enumeration macro has one parameter, which is also a macro that takes the enumerated item as an argument and performs the corresponding operations.  Taking FBlendTwoWayTrait as an example:      The locally defined TRAIT_INTERFACE_ENUMERATOR macro enumerates all the trait interfaces implemented by FBlendTwoWayTrait and passes these interfaces to the GeneratorMacro parameter.  Combining with the nested macros in GENERATE_ANIM_TRAIT_IMPLEMENTATION:  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT defines the memory size and alignment for shared and instance data, as well as the constructor and destructor.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_GET_LATENT_PROPERTY_MEMORY_LAYOUT defines the function to retrieve the memory layout information for Latent Property.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_IS_PROPERTY_LATENT defines the function to determine whether the property with the corresponding name is a Latent Property.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_GET_INTERFACE defines the function to retrieve a pointer to the specified trait interface.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_GET_INTERFACES defines the function to retrieve the IDs of all implemented trait interfaces.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_GET_REQUIRED_INTERFACES defines the function to retrieve the IDs of all required trait interfaces.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_ON_TRAIT_EVENT defines the function to respond to the required trait event callbacks.  ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT_GET_TRAIT_EVENTS defines the function to retrieve the IDs of all responsive trait events.  At this point, the necessary trait definitions for the framework has been automatically generated.  AUTO_REGISTER_ANIM_TRAIT, similar to AUTO_REGISTER_ANIM_TRAIT_INTERFACE, registers the trait this time.     Trait registration does not use shared pointers, but is constructed from the callback of UE::AnimNext::TraitConstructorFunc with the DestPtr address passed in.   Latent Property  Latent Property is the part of shared data that needs to be instantiated, placed after the FInstanceData section.  For shared data that inherits from FAnimNextTraitSharedData, you need to use the GENERATE_TRAIT_LATENT_PROPERTIES macro to manually、selectively register the properties that should be marked as Latent Property:    This macro also uses an enumeration macro as a parameter, within which it nests the macro:  ANIM_NEXT_IMPL_DEFINE_LATENT_CONSTRUCTOR uses placement new to individually construct Latent Property (the memory address is discussed in the following section on FNodeInstance).     See: FExecutionContext::AllocateNodeInstance for how it allocates memory, constructs instance data, and Latent Property    GENERATE_ANIM_TRAIT_IMPLEMENTATION-ANIM_NEXT_IMPL_DEFINE_ANIM_TRAIT-ConstructTraitInstance    GENERATE_TRAIT_LATENT_PROPERTIES-ANIM_NEXT_IMPL_DEFINE_LATENT_CONSTRUCTOR-ConstructLatentProperties   ANIM_NEXT_IMPL_DEFINE_LATENT_DESTRUCTOR Destruct Latent Property one by one  ANIM_NEXT_IMPL_DEFINE_GET_LATENT_PROPERTY_INDEX Query the index of the Latent Property for the corresponding offset     FAnimNextTraitSharedData::GetLatentPropertyIndex comments mentioned: If the Latent Property corresponding to the offset can be found, it returns the index starting from 1; if not found, it returns the number of Latent Property, which is less than or equal to 0 (needs to be negative)   ANIM_NEXT_IMPL_DEFINE_LATENT_GETTER generates a getter function for retrieving property values from FTraitBinding for each Latent Property     Magic of Macro ! It uses the constexpr function GetLatentPropertyIndex to get the LatentPropertyIndex, and then get the Latent Property reference from the Binding.   TraitEvent Trait Events  FAnimNextTraitEvent is the base class for trait events.    DECLARE_ANIM_TRAIT_EVENT, similar to traits and trait interfaces, declares and defines EventUID, and additionally supports the IsA functionality, serving as a simple alternative mechanism for RTTI.     Since FAnimNextTraitEvent is USTRUCT, the IsA should not be necessary. This may be for performance or other considerations.   Trait events are similar to UI click events and can be marked as Handled, with the option to set a valid duration or an infinite duration, among other settings.  Global Registry  FTraitRegistry  The global registry for trait objects.  When registering traits using macros, FTraitRegistry prioritizes the default allocated 8KB size StaticTraitBuffer to store traits. If this limit is exceeded, it uses DynamicTraits for storing new trait, which is an optimization for memory locality.     There is an interesting little detail here. The DynamicTraits array stores uintptr_t instead of void* or FTrait*, which means using integers to store pointers.    Because integers are used, index of array can be stored at the same time to implement the subsequent FreeList mechanism:    When DynamicTraitFreeIndexHead is valid, DynamicTraits[DynamicTraitFreeIndexHead] stores the next reusable array element   Additionally, several Maps are stored to speed up queries.  FTraitRegistry::Register is used to register traits to DynamicTraits.  FTraitInterfaceRegistry  The global registry for trait interface objects.  In comparison, FTraitInterfaceRegistry is quite straightforward, simply a map from interface IDs to smart pointers.  Node     rough memory layout，drawing with drawio   This section introduces some key types related to nodes.  FNodeTemplate  A FNodeTemplate is a combination of a set of traits, which can include multiple sets of base + additive traits. All animation graphs can share the same template object.    The traits that make up the node template are stored as FTraitTemplate objects at the end of the contiguous memory of the FNodeTemplate object.       FNodeTemplateBuilder::BuildNodeTemplate constructs an FNodeTemplate object and the FTraitTemplate contained in it in a contiguous buffer of TArray&lt;uint8&gt;   From it, you can obtain the UID, base address of the trait array, the number of traits, and other information.     FNodeTemplate::NodeSharedDataSize is the size of the shared data for all traits (including the FLatentPropertiesHeader of the base trait) after alignment.   FNodeTemplate::NodeInstanceDataSize is the size of the instance data for all traits after alignment.     FTraitTemplate  FTraitTemplate is the trait within the node template. In addition to providing basic information about the trait such as UID, trait type, shared/instance data, number of subtraits, and number of Latent Properties, it also allows you to obtain the offset of the shared data, the offset of the pointer to the shared latent property array, and the offset of the instance data.       See：FNodeTemplate::Finalize      I think the naming of the two member functions FTraitTemplate::GetTraitDescription is a bit confusing. The more understandable name should be GetTraitSharedData, which is used to get the shared data pointer of the trait. It may be a typo or a name change.   FNodeDescription  The only read-only data within an animation graph. Although the object itself is 8 bytes in size, when allocating memory, it includes the size of the shared data from the traits on the node, making it an object whose size varies in usage.       See：    FTraitReader::ReadGraphSharedData    and some other details: FNodeDescription::Serialize FTrait::SerializeTraitSharedData FTraitWriter::WriteNode FTrait::SaveTraitSharedData    After reading, it is stored in UAnimNextAnimationGraph::SharedDataBuffer. For usage, refer to FExecutionContext::GetNodeDescription      FNodeDescription::TemplateHandle is used to obtain an instance of the FNodeTemplate object from FNodeTemplateRegistry.   FNodeDescription::NodeInstanceDataSize contains the size of the instantiation data, plus the total size of all Latent Properties.      Note the difference between FNodeDescription::NodeInstanceDataSize and FNodeTemplate::NodeInstanceDataSize    In addition, FNodeDescription and FNodeTemplate are many-to-one, which can be understood from their usage.   FNodeInstance  The instantiated data of the node, dynamically created at runtime, has a size of 16 bytes itself. When allocating memory, it includes the size of the instantiated data of the traits and their Latent Property size, which is also an object that varies in size depending on usage; built-in reference counting.       For usage, refer to ：FAnimationAnimNextRuntimeTest_TraitSerialization::RunTest，FExecutionContext::AllocateNodeInstance   FNodeTemplateRegistry  The global registry of the FNodeTemplate object, ensuring that all FNodeTemplate instances are contiguous in memory.  FTraitStackBinding  Describes the data required for a set of traits (one base trait and its children/additive traits) used to query traits or the trait interface.     See：FTraitStackBinding::FTraitStackBinding，especially the last few lines   For example, FTraitStackBinding::GetInterfaceImpl: attempts to find the trait that implements the specified InterfaceUID from the trait stack and returns the binding of that trait.  FTraitBinding  Describes the data of a specific trait within a set of traits, allowing you to query whether the current trait implements the specified trait interface.  TTraitBinding  Strongly typed/type-safe FTraitBinding.  FExecutionContext  Since traits are stateless, the dynamic data/instance data during execution requires an object to hold it, which is the FExecutionContext, the execution context object.  It is used to bind to a graph instance and provides a unified trait query interface for nodes.  The Update and Evaluate processes of the graph are encapsulated in the execution function of a RigVM node: FRigUnit_AnimNextRunAnimationGraph_v2_Execute().  FUpdateTraversalContext  The derived context object used when updating the graph.  Internally, it uses a stack (LIFO) allocated on the MemStack to implement a depth-first traversal of the trait tree, rather than the recursive method used in ABP.     See: UE::AnimNext::UpdateGraph. Each trait is executed twice in the while loop, corresponding to IUpdate::PreUpdate and IUpdate::PostUpdate.    IUpdate::OnBecomeRelevant is also called here.   FEvaluateTraversalContext  The derived context object used when evaluating the graph.  The internal FEvaluationProgram is used to store the FAnimNextEvaluationTask that each node needs to execute while traversing the graph. It then calls FEvaluationProgram::Execute to perform each evaluation task on the FEvaluationVMStack.     See: UE::AnimNext::EvaluateGraph, the execution process is similar to UpdateGraph   FAnimNextEvaluationTask  FAnimNextEvaluationTask is a logical object that can be reused between traits, representing micro-instructions running on the evaluation virtual machine, which can handle input and output at the same time through the internal state of the virtual machine (also a stack).  UAF Modules  UAF consists of multiple modules:    On the ue5-main branch, the prefix of the series of module names has changed from AnimNext to UAF.    Among them: UAF/AnimNext: Provides core animation utility functions, defines base class interfaces, etc. For example: UE::AnimNext::FDecompressionTools::GetAnimationPose  UAFAnimGraph/AnimNextAnimGraph: Implements RigVM-based functionality related to animation graphs.  These two modules are the main focus of this article.  Other modules introduce functionalities from other modules/systems to UAF, such as incorporating StateTree, PoseSearch, etc.  SoA (struct of array)  Each utility function in TransformArrayOperations.h has both AoS and SoA versions, with the code prioritizing the use of AoS. This indicates that in terms of data structure design, UAF is more data-oriented.  Conclusion  UAF is a redesigned, data-oriented, composition-oriented, high-performance, flexible, concise, and easily extensible animation framework.  It completely abandons the ABP framework and embraces RigVM.  Due to its feature set still being in development, it is currently in an experimental phase.  Miscellaneous  Writing Animation Blueprints in Code  Refer to code of test cases from UAFTestSuite/AnimNextTestSuite and UAFAnimGraphTestSuite/AnimNextAnimGraphTestSuite modules.  Playing “Montages” in UAF  Due to the length of this article, I decide to not to elaborate further.  The relevant nodes are UInjectionCallbackProxy, UPlayAnimCallbackProxy.  The related code can be found in UE::AnimNext::FInjectionUtils::Inject.  Official FAQ Link  Unreal Animation Framework (UAF, AnimNext) FAQ "
  },
  
  {
    "title": "How to get MontageInstance correctly",
    "url": "/posts/Get-Montage-Instance/",
    "categories": "Unreal Engine, Animation",
    "tags": "gameplay, animation, tutorial",
    "date": "2025-08-05 01:00:00 +0800",
    "content": "Terms  Montage  refers to UAnimMontage Object  MontageInstance  refers to FAnimMontageInstance Object  Get the MontageInstance  GetInstanceForMontage - Find first matching MontageInstance  Finding from UAnimInstance::MontageInstances  GetActiveInstanceForMontage - Find the active MontageInstance  Finding from UAnimInstance::ActiveMontagesMap  Simple Logic Flow    You can see that after playing a montage,  the newly generated montage instance can be obtained through any of the interfaces above,  After stopping/blending out, the montage instance, is no longer considered active,  After the playback is complete/the montage is actually stopped, it cannot be obtained by any means.  But in a short period of time, when the same montage is played multiple times, things start to get a little more complicated,  Suppose that when playing, bStopAllMontages is true, which is stopping the old playing montage.  For GetInstanceForMontage    Since the engine implementation is return the first montage instance whose asset is the incoming montage,  Then, if there are multiple montage instances blending out with the same montage asset, you can only get the blending out one through this interface, not the “active instances” you may need, because the active instance always get added to the end of the array. GetActiveInstanceForMontage should be used in this case  GetMontageInstanceForID - Finding with InstanceID  In addition, engine provides this interface to support searching specific instance using FAnimMontageInstance::InstanceID which is unique within the process  Suggestion  Because the GetActiveInstanceForMontage interface is queried through a map instead of traversing an array, it is the fastest.  If you just need to find a montage instance that is playing and not blending out/active, query it using the montage pointer and the GetActiveInstanceForMontage interface.  These is only one active montage instance at most, because montage and montage instance is one-to-one mapped with map.    For inactive montage searches, you can consider caching FAnimMontageInstance::InstanceID for accurate searches to avoid the problem of finding the wrong object when playing the same montage multiple times "
  },
  
  {
    "title": "Latent Timer",
    "url": "/posts/Latent-Timer/",
    "categories": "Unreal Engine, Plugins",
    "tags": "gameplay, remcommon, tutorial, documentation",
    "date": "2024-10-05 13:14:52 +0800",
    "content": "Latent timer  Why “reinventing the wheel” while we have TimerManager  Well, TimerManager has many problems when it comes to gameplay:          SetTimerForNextTick actually called this tick rather than the next tick           Callback order is not guaranteed to be the same as the timer set order           Can’t specify tick group when setting timer           TimerManager::Tick itself is hardcoded in some late time of a frame           Only support delay in time seconds, do you want to delay in frames?           Don’t support loop count           FTimerDta is still quite bloated, with size optimization done on FTimerUnifiedDelegate      Could we solve all the problems?  Well, well, solving 100% of them is hard, but 90% is piece of cake with our great savior — FLatentActionManager  FLatentActionManager is a simple but powerful tool to tick any instance of FPendingLatentAction every frame.  Every LatentAction is bound to a UObject, it ticks in the tick group of the bound object ! Or “by the end of frame” if tick disabled for the bound object where is just near and ahead of TimerManager::Tick.  FPendingLatentAction could be derived to do anything you want. Eg: FDelayUntilNextTickAction, FDelayAction they are the heroes behind the beloved delay node in blueprint.  The way I solve it with Rem::Latent::FTimerLatentAction_Delay          Providing Rem::Latent::SetTimerForThisTick and Rem::Latent::SetTimerForNextTick for maximum explicitly and flexibility when expressing delay a tick           Latent Action is processed in the order they get bound to the UObject           The tick group of a Latent Action could be controlled by specifying a ticking object within the target tick group. And it support specifying tick dependency with no efforts!           Support delay in frames! Which doesn’t likely to exist in TimerManager. Two helper struct: FTimerParameterHelper_Time, FTimerParameterHelper_Frame, one API: Rem::Latent::SetTimer           Support specific loop count : FTimerParameterHelper_Time::LoopCount, FTimerParameterHelper_Frame::LoopCount           Support counting from next frame: see FTimerParameterHelper_Time::bSkipCountingThisFrame           My FTimerLatentAction_Delay only has size of 40 bytes to get all the jobs done, while FTimerDta has the size of 128, 3.2x bigger!           A fire and forget alternative for pausing timer for one frame pause: Rem::Latent::SetTimerPausedOneFrame           Familiar APIs: Rem::Latent::PauseTimer, Rem::Latent::UnpauseTimer, Rem::Latent::SetTimerPaused(did we met before?), Rem::Latent::StopTimer, Rem::Latent::FindTimerAction           Re-triggerable is natively supported: Rem::Latent::ResetTimerDelay, support both delay in time and in frame           Call count compensation and opting out it with FTimerParameterHelper_Time::bMaxOncePerFrame (Same as what’s in TimerManager)           27 bits wasted for now, they are the hope for the future!      Limitations          Rem::Latent::FTimerHandle is 32-bit, because FLatentActionManager::AddNewAction only accepts int32, while it was uint64 in TimerManager           Infinite loop map happen if Rem::Latent::SetTimerForThisTick is called on the same object within FLatentActionManager::ProcessLatentActions, use Rem::Latent::SetTimerForNextTick instead in the case           Rem::Latent::SetTimerForThisTick will not get called in the relevant tick group, if the bound object is already ticked this frame, consider Rem::Latent::SetTimerForNextTick instead in the case           TimeToDelay, LoopCount, InitialDelay are all 4 bytes only for simplicity, might consider extended to those 27 spared bits in the future           Requires tick enabled on the bound object to “set tick group” for our timer latent action      Sample code  void UYourObject::DoJob() {     auto TimerHandle = Rem::Latent::SetTimerForThisTick(*this,         FTimerDelegate::CreateUObject(this, &amp;ThisClass::Callback)); }   void UYourObject::TryDoJobUntilSucceed() {     bool bWantToRetry{true};      ON_SCOPE_EXIT     {         if (bWantToRetry)         {             Rem::Latent::SetTimerForNextTick(*this, FTimerDelegate::CreateWeakLambda(this,             [this]             {                 TryDoJobUntilSucceed();             }));         }     };      // ... }   void UYourObject::RetriggerableJob() {     // ...      if (!TimerHandle.IsValid())     {         TimerHandle = Rem::Latent::SetTimer(*this, FTimerDelegate::CreateWeakLambda(this, [this]         {             // ...             Rem::Latent::StopTimer(*this, TimerHandle);             TimerHandle = {};         }), {.TimeToDelay = 1.0f, .LoopCount = 0/*loop infinite*/});     }     else     {         Rem::Latent::ResetTimerDelay(*this, TimerHandle);     } }  "
  },
  
  {
    "title": "Re:RemGameplayCamera from zero",
    "url": "/posts/RemGameplayCamera-from-zero/",
    "categories": "Unreal Engine, Plugins",
    "tags": "gameplay, remgameplaycamera, tutorial, documentation",
    "date": "2024-02-25 00:21:20 +0800",
    "content": "Preface  This page is a simple and clear tutorial for RemGameplayCamera plugin  It would cover the very basics you need to use the plugin  Hope you will like it  (I will continue to improve this page, and any feedback or contribution is welcomed)  Introduction  RemGameplayCamera plugin is a data-driven gameplay camera system for unreal engine projects. It provides a state based(tag based), modular, prioritized camera data configuration with data asset, support real time editing  Built on top of the existing camera framework make it full compatible with camera sequence, camera shake, view target switching and other camera effects.  It’s AActor based, so any actor class could use it (UAbilitySystemComponent is required for now).  With built-in camera location, rotation smoothing (lag) and many other mechanisms, you can easily implement camera system like what’s in ALS or Lyra by just tweaking the camera configurations without writing a line of code.  It also come with some basic functionality for free look, enemy lock, mesh fading gradually and post processing management, with extensibility in mind.  The camera data processing pipeline is divided into several parts, every part of these could be extended with blueprint or code!  You could easily implement something like speed based fov, speed based camera offset.  Note: (currently) It rely on the ability system component from the view target to provide gameplay tag event-driven camera data update, in this way, it’s also loose-coupled with the rest of the game world.  0. Starting from Third Person template  Not actually from zero😀, I will guide you to do a simple walk through on the RemGameplayCamera system by trying to replace the default camera in the “Third Person Template”.  1. Copy files in Config directory into your project  Assuming you’ve created the Third Person project and put RemGameplayCamera plugin in place.  Please copy RemGameplayCamera/Config folder to YourProject/Config folder, these are the default GameplayTag configs for the system. It will register these default tags into the system, and get the URemCameraSettings object configured.  You could check it by navigating to Project Settings -&gt; Game -&gt; Rem Camera Settings after opening the editor. And customize it if you want.  2. Option-in the third person character  By Default, the “rem camera system” is disabled for every view target.  View target actor that wants to use the system should have RemTickCamera in their AActor::Tags property to be able to get identified.  So, go ahead and open BP_ThirdPersonCharacter, and add it from the detail panel:   3. Create essential files  In order to use the Rem camera system, we need to use the ARemPlayerCameraManager and prepared the “camera data” for it.  create BP_RemCameraManager  So, first, let’s create this camera manager blueprint named “BP_RemCameraManager” that derived from ARemPlayerCameraManager class. It’s this class that coordinate the camera system.  create BP_PlayerController  In order to utilize the BP_RemCameraManager, create a player controller blueprint named “BP_PlayerController” that derived from APlayerController and assign “BP_RemCameraManager” to it’s Player Camera Manager Class property:   create BP_GameMode  In order to utilize the BP_PlayerController, create a game mode blueprint named “BP_GameMode” that derived from AYourProjectNameGameMode and assign “BP_PlayerController” to it’s Player Controller Class property:   create camera data files  BP_RemCameraManager need camera data to work as expected.  Camera data is organized by a simple hierarchy:    URemCameraSettingForViewTargets has all the camera settings for all the view targets in the game. Referenced by the ARemPlayerCameraManager. It’s the top or root node of the hierarchy.   URemCameraSettingAssetsForViewTarget has camera settings for a kind of view target. Referenced by the URemCameraSettingForViewTargets.   URemCameraSettingAsset is where the actual camera setting values resides. Referenced by the URemCameraSettingAssetsForViewTarget.   create DA_Camera_Setting  First, we create a data asset named DA_Camera_Setting of type URemCameraSettingAsset,  copy these value and paste into State Query property:  (TokenStreamVersion=0,TagDictionary=,QueryTokenStream=(0,1,6,1,1,0),UserDescription=\"\",AutoDescription=\" NONE(  ANY( ) )\")   this will make the tag query always matching, letting the camera setting asset we create take effect.     Normally, this should match specific view target state which is represented as gameplay tag   then, copy these value and paste into Setting Values property:  ((Comment=\"CameraSettingValue.CameraTransform.Location.Offset\",SettingTag=(TagName=\"CameraSettingValue.CameraTransform.Location.Offset\"),Value=/Script/RemGameplayCamera.RemCameraDataLocationOffset_Fixed(Offset=(X=280.000000,Y=0.000000,Z=0.000000))),(Comment=\"CameraSettingValue.Fov.Value\",SettingTag=(TagName=\"CameraSettingValue.Fov.Value\"),Value=/Script/RemGameplayCamera.RemCameraDataFov_Fixed(Fov=90.000000)),(Comment=\"CameraSettingValue.PivotTransform.Value\",SettingTag=(TagName=\"CameraSettingValue.PivotTransform.Value\"),Value=/Script/RemGameplayCamera.RemCameraDataTransform_MeshTransform(SocketName=\"spine_05\",Offset=(X=0.000000,Y=0.000000,Z=0.000000))),(Comment=\"CameraSettingValue.Trace\",SettingTag=(TagName=\"CameraSettingValue.Trace\"),Value=/Script/RemGameplayCamera.RemCameraDataTrace_Collision(TraceRadius=15.000000,TraceDistanceRatioInterpolationSpeed=10.000000,TraceStartLocationAlpha=(Curve=(),BlendTime=1.000000),TraceStartTransform=None)),(Comment=\"CameraSettingValue.CameraTransform.Location.Blend\",SettingTag=(TagName=\"CameraSettingValue.CameraTransform.Location.Blend\"),Value=/Script/RemGameplayCamera.RemCameraDataBlendAlpha_Blend(Blend=/Script/RemGameplayCamera.RemCameraAlphaBlend(Blend=(Curve=(),BlendTime=1.000000)))))   these values tries to mimic the spring arm settings on BP_ThirdPersonCharacter.  create DA_Camera_ViewTarget  Now that the setting asset is ready, we gonna create another data asset named DA_Camera_ViewTarget of type URemCameraSettingAssetsForViewTarget. It specifies the setting assets to use for our character.  For the View Target Tag Query property, we would use the same value up there👆 as DA_Camera_Setting::State Query as we simply want it to be matched and used.     Normally, this should match specific view target identifier which is also represented as gameplay tag   then add an element in SettingAssetsForStatesData, add the DA_Camera_Setting to it’s SettingAssets property (bUseSettingAssetsGroupsis a relatively advanced feature that’s added recently，we’ll ignore it here，let it be unchecked，so we could use the simpler one as opposed to it. See detailed explanation bellow if interested)  create DA_Camera_ViewTargets  Finally, we create the last data asset named DA_Camera_ViewTargets of type URemCameraSettingForViewTargets. It has all the camera data about every view targets in the game.  Add the DA_Camera_ViewTarget to it’s Settings for View Targets property, that’s it.  Last but not least, assign DA_Camera_ViewTargets to the BP_RemCameraManager::CameraSettingForViewTargets property.    4. PIE, start!  After changing the game mode to BP_GameMode, and hit Play  You may find the camera following character’s spine movement, more visible when it landing. And the camera has a smoothing effect when getting away from a colliding object (ALS like).  After typing the console command Rem.Camera.DrawDebug.Shape 1, a blue sphere would show up around the spine of the character indicating the Pivot Location which is the same with ALS.    5. Congratulations  thanks for your time  ♥  Want to know more ?  How the camera location get calculated    This👆 image contains terms that is crucial to understand the system, anytime feeling confused, you can refer to it or asking for help in our group.  Every piece of the data that is needed by the camera pipeline could be extended.  There are also many built-in functionalities for you, feel free to explorer it!     For more information, please look at the tooltips of properties on URemCameraSettings and FRemCameraSettingTagValue   SettingAssetsForStatesData a subdivision of configuration for a kind of view target  Prior to the 3.2 release, there was one and only one set of camera configurations in the configuration of a view target  When view target has different camera configurations in different states, it is necessary to include all camera configurations, which is difficult to maintain and use  It is now possible to configure the set of camera configurations separately for each combination state. When the combination state changes, the configuration is automatically switched, thus solving the above two problems  For example, instead of having all the camera configurations for all the movement modes in one array, you can configure a set of configurations for each movement mode.     Of course, no one is stopping you from doing that, but apparently the later is better in the long run   Get bUseSettingAssetsGroups checked to use the configuration grouping feature  In version 3.2, I added the SettingAssetsGroups property to SettingAssetsForStatesData to support reusing camera configurations in different states for the view target  Using the URemCameraSettingAssetGroup type, the camera configurations are freely combined to get the desired set of Camera Configurations  Each Configuration Group can choose to add a subgroup of camera configurations to the front or back of the current set of camera configuration, or any specific camera configuration asset    Modify the engine to support camera data type filtering  Need to contact me to get access to the source code repository, because it is required to modify the code of both the engine and plugin  follow the steps：     apply the patch from the root directory of the repository to the engine   edit the REM_ENABLE_CAMERA_DATA_DROP_DOWN_FILTER macro in the plugin code to true   to get automatically data type filtering according to the selected camera setting tag    as you can see, only the data related to transform is listed "
  },
  
  {
    "title": "Inside FGameplayTagQuery",
    "url": "/posts/Inside-FGameplayTagQuery/",
    "categories": "Unreal Engine",
    "tags": "gameplay",
    "date": "2023-11-13 01:13:14 +0800",
    "content": "What is FGameplayTagQuery  Quoted from source code comments:     An FGameplayTagQuery is a logical query that can be run against an FGameplayTagContainer.  A query that succeeds is said to “match”. Queries are logical expressions that can test the intersection properties of another tag container (all, any, or none), or the matching state of a set of sub-expressions (all, any, or none). This allows queries to be arbitrarily recursive and very expressive.  For instance, if you wanted to test if a given tag container contained tags  ((A &amp;&amp; B) || (C)) &amp;&amp; (!D), you would construct your query in the form ALL( ANY( ALL(A,B), ALL(C) ), NONE(D) )   Why use FGameplayTagQuery  Because when using FGameplayTagQuery for logical matching, the number of tags and matching logic can be arbitrary, and it supports nesting on logic, unlike:    FGameplayTag limits the use of only 1 tag (although in addition to match itself, it can also be used to match parent tags)   FGameplayTagContainer has only limited matching logic (which is one of AND, OR, NOT, depends on how the code is used)   Before FGameplayTagRequirements was added to the FGameplayTagRequirements::TagQuery member, it had only two FGameplayTagContainer members, corresponding to the “AND” and “NOT” matching logic, which is still limited (after the time of TagQuery member added, you can use FGameplayTagRequirements ::ConvertTagFieldsToTagQuery to obtain a Query object which is the logical combination of two tag containers)   Implementation of FGameplayTagQuery  data structure          TokenStreamVersion version number, retains data to facilitate subsequent possible implementation changes, corresponding to the enumeration type EGameplayTagQueryStreamVersion           TagDictionary The tag array after deduplication, which comes from the tags that need to be used in logical expressions           QueryTokenStream is a set of metadata that stores the version number (redundant storage), whether there is a logical expression expression, the logical expression type, the number of tags used, and the index in TagDictionary. It is the key to achieving memory-efficient and fast evaluation.           UserDescription string, customized description information           AutoDescription string, automatically generated description information      Generation method  Use C++ to construct query objects  Use the Builder Pattern API to construct logical expressions: \tFGameplayTagQuery TagQuery; \tconst FGameplayTagContainer TagContainerA{}; \tconst FGameplayTagContainer TagContainerB{}; \tconst FGameplayTag TagC{};  \tTagQuery.Build(FGameplayTagQueryExpression().AllExprMatch() \t\t.AddExpr(FGameplayTagQueryExpression().AnyTagsMatch().AddTags(TagContainerA)) \t\t.AddExpr(FGameplayTagQueryExpression().NoExprMatch() \t\t\t\t.AddExpr(FGameplayTagQueryExpression().NoTagsMatch().AddTags(TagContainerB)) \t\t\t\t.AddExpr(FGameplayTagQueryExpression().AnyTagsMatch().AddTag(TagC))), FString{TEXTVIEW(\"Test Logic\")});  \t// Randomly written logic, it is not recommended to try to understand it \t// I use indentation levels to represent nesting levels, and one line in each level defines a logical expression   Brief process of FGameplayTagQuery::Build:    Write the version number and user description information, and reset those key data   Write the “version number” and “whether it contains a logical expression” information to elements 0 and 1 of QueryTokenStream   Parse the logical expression and write the enumeration of the expression type in QueryTokenStream, which is of type EGameplayTagQueryExprType. For “non-nested expression”, write the array number of tags used by it, then add each tag to TagDictionary which is deduplicated, and write the index; for “nested expression”, parsing it recursively   To put it simply, the Build process uses depth-first traversal to flatten the logical expressions of the tree structure into an array.  Use the editor to construct the query object  The underlying logic is consistent with the C++ structure, except that because FGameplayTagQueryExpression is not USTRUCT, and InstancedStruct has not yet been born, it is “mirrored” with UObject (personal guess), so there are UEditableGameplayTagQueryExpression and related types to support expression nesting during editing and providing better debugging information, you can refer to FGameplayTagQuery::BuildFromEditableQuery  FGameplayTagQuery::Matches, test the logical expressions  The auxiliary type FQueryEvaluator is used to hold the immutable reference of TagQuery, record the current metadata index and detect whether there are read errors. According to the read expression type, the corresponding logical definition is executed. Every time the token array is read, it will detect whether there is a read error. You can refer to FQueryEvaluator::EvalExpr  Conclusion I feel that the implementation of FGameplayTagQuery is quite clever and provides powerful matching logic, which is suitable for any needs that require Tag matching functionality. However, the editor logic contains code duplication, is not elegant enough, and the detection of reading errors is not rigorous, so the follow-up, frequent testing is not that necessary. But overall, flaws do not cover up strengths. "
  },
  
  {
    "title": "A way to combine multiple unreal projects into one",
    "url": "/posts/A-way-to-combine-multiple-unreal-projects-into-one/",
    "categories": "Unreal Engine",
    "tags": "tooling",
    "date": "2022-06-05 11:15:13 +0800",
    "content": "Use the GenerateProjectFiles.bat and .uprojectdirs files of the engine directory     First refer to the comments in the Default.uprojectdirs file   Create a new my.uprojectdirs or directly modify the Default.uprojectdirs file and write to e.g. Project/   When you run GenerateProjectFiles.bat build a solution, you will additionally look for Unreal Project directories from the Level 1 subdirectory of the Engine Directory/Project directory, such as UnrealEngine/Project/LyraGame finish      Because only subdirectories can be specified in the .uprojectdirs file, if you want projects in external directories to be included in the solution file, you can use the symbol-link functionality provided by the system       Deprecated    Original intention    For working and studying purpose, I have multiple Unreal Projects on my computer, and they share the same engine    By default, each project file is a stand-alone solution file generated by UBT(Unreal Build Tool)    This brings me some problems:                Due to the high cost of opening a solution, the waiting time and memory footprint may get multiplied when opening multiple solutions at the same time                 When the IDE is bugged, or the engine code is updated and triggering “symbol reparsing”, It takes at least 15 minutes to boot up, which is really a torture            I think that different project solutions should treat the project with same physical path as the same project, the Unreal Engine project file should not be re-parsed in each solution    But both of the Rider and Visual Studio (the most powerful IDE of the universe;) will get it re-parsed in every solution. It is very tortuous and makes me confused, hoping some expert could explain the reason behind this    Demand    So I was thinking: since these IDEs are “stupid” and unreliable, could I find a way to manually combine multiple solutions into one?    Steps    I am sharing the steps to accomplish the job using Rider:                Among the solutions that you want to open together, choose the one you like as the main solution, open it up                 Add other project files                        In Explorer, the solution browser, right-click any project folder, such asGames, select Add, Add Existing Project..., and choose the relative project file                 Assuming we are adding the LyraStarterGame project, then these files should locate at LyraStarterGame_Folder\\\\Intermediate\\\\ProjectFiles\\\\LyraStarterGame.vcxproj                 In “Solution Configuration”, modify the configuration of the project just added                   in the toolbar of the upper right corner, click DebugGameEditor | Win64 button (this is my Solution Configuration, the text of the button would be different according to your configuration), and select Edit Solution Configurations...                 find the project just added, you should notice that they are default configured as something like DebugClient | Arm64, change it to what you need, generally it should be the same as Solution Configuration                 Modify the project file parameter                   back to Explorer, the solution browser                 right-click the project just added (again, using LyraStarterGame as an example), select Edit, Edit LyraStarterGame.vcxproj                 replace all the $(SolutionDir) with $(ProjectDir)..\\\\..\\\\ in LyraStarterGame.vcxproj ($(SolutionDir) is the root path of current solution, $(ProjectDir) is the root path of current project file, which is LyraStarterGame_Folder\\\\Intermediate\\\\ProjectFiles\\\\, using ..\\\\ twice, we get the root path of current project)                 if you don’t want to replace all of them at once, searching your “build configuration” such as DebugGame_Editor|x64, find the relevant configuration, you can only replace the text within the three NMake command lines, but probably encounter some problems because of can not parse the project file correctly: for example Switch Header/Source is not working, grammar coloring is broken. If so, do a full replacement should solve the problem            Limitation    Every time the project file is regenerated, the relative file would be overriden and the steps above need to be re-done. If any IDE could support this or having a tool to automated this, life would be much easier   "
  }
  
]

